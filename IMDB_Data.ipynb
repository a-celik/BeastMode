{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/aclImdb/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/Stephen/Documents/BeastMode'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500\n"
     ]
    }
   ],
   "source": [
    "# get all neg urls\n",
    "with open('aclImdb/train/urls_pos.txt', 'r') as f:\n",
    "    train_pos_urls = f.readlines()\n",
    "    print len(train_pos_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_movie(url):\n",
    "    pageText = requests.get(url)\n",
    "    while (pageText == None):\n",
    "        time.sleep(10)\n",
    "        pageText = requests.get(url)\n",
    "    soup = BeautifulSoup(pageText.text,\"html.parser\")\n",
    "    return soup.find(\"div\",attrs={\"id\":\"tn15title\"}).find(\"a\").get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1e+03 ns, total: 4 µs\n",
      "Wall time: 7.87 µs\n",
      "88\n",
      "188\n",
      "289\n",
      "441\n",
      "517\n",
      "585\n",
      "693\n",
      "725\n",
      "853\n",
      "917\n",
      "946\n",
      "975\n",
      "1012\n",
      "1051\n",
      "1182\n",
      "1308\n",
      "1483\n",
      "1529\n",
      "1700\n",
      "1734\n",
      "1876\n",
      "1883\n",
      "1982\n",
      "2201\n",
      "2247\n",
      "2282\n",
      "2425\n",
      "2544\n",
      "2962\n",
      "2968\n",
      "3066\n",
      "3070\n",
      "3167\n",
      "3188\n",
      "3222\n",
      "3259\n",
      "3441\n",
      "3492\n",
      "3551\n",
      "3559\n",
      "3815\n",
      "3853\n",
      "3889\n",
      "3962\n",
      "3982\n",
      "3989\n",
      "4004\n",
      "4012\n",
      "4191\n",
      "4276\n",
      "4340\n",
      "4515\n",
      "4655\n",
      "4919\n",
      "5003\n",
      "5018\n",
      "5150\n",
      "5163\n",
      "5252\n",
      "5296\n",
      "5502\n",
      "5521\n",
      "5564\n",
      "5800\n",
      "5855\n",
      "5983\n",
      "5997\n",
      "6547\n",
      "6668\n",
      "6682\n",
      "6696\n",
      "6760\n",
      "6844\n",
      "7033\n",
      "7069\n",
      "7111\n"
     ]
    }
   ],
   "source": [
    "% time\n",
    "import random\n",
    "# Make a dictionary of URL: movie name\n",
    "url_dict = dict(zip(train_pos_urls, [None]*len(train_pos_urls)))\n",
    "i = 0\n",
    "for url in train_pos_urls[5275:]:\n",
    "    if url_dict[url] == None:\n",
    "        url_dict[url] = get_movie(url)\n",
    "    if random.random() < 0.01:\n",
    "        print i\n",
    "    i += 1\n",
    "    time.sleep(0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we did this right, the number of keys in `url_dict` should be equal to the number of unique urls in `train_pos_urls`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1390 1390\n"
     ]
    }
   ],
   "source": [
    "n_url_keys = len(url_dict.keys())\n",
    "n_unique_urls = len(list(set(train_pos_urls)))\n",
    "print n_url_keys, n_unique_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the results in a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "fp = open(\"url_movie_tr_pos.json\",\"w\")\n",
    "json.dump(url_dict, fp)\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a review data frame\n",
    "review_df = pd.DataFrame(columns=['movie_id', 'stars', 'positive', 'text', 'url', 'movie_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_pos_names = list(os.walk('aclImdb/train/pos/'))[0][2]\n",
    "for review in train_pos_names:\n",
    "    stars = int(review.split(\"_\")[1].split(\".\")[0])\n",
    "    movieID = int(review.split(\"_\")[0])\n",
    "    fp = open('aclImdb/train/pos/%(review)s' % {'review': review}, 'r')\n",
    "    text = fp.read()\n",
    "    pos = True\n",
    "    url = train_pos_urls[movieID]\n",
    "    movie_name = url_dict[url]\n",
    "    reviewDict = {'movie_id': movieID, 'stars': stars, 'positive': pos, 'text': text, 'url': url, 'movie_name': movie_name}\n",
    "    review_df = review_df.append(pd.DataFrame(reviewDict),index=[0])\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
