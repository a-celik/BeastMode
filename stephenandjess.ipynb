{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import glm, ols\n",
    "\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's first open our data frame of all relevant movies movies.\n",
    "with open(\"IMDB_dftouse_dict.json\", \"r\") as fd:\n",
    "    IMDB = json.load(fd)\n",
    "IMDB_df = pd.DataFrame(IMDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>movie_name</th>\n",
       "      <th>positive</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10027</td>\n",
       "      <td>Titanic</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "      <td>Sure, Titanic was a good movie, the first time...</td>\n",
       "      <td>http://www.imdb.com/title/tt0120338/usercommen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10028</td>\n",
       "      <td>Titanic</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>When I saw this movie I was stunned by what a ...</td>\n",
       "      <td>http://www.imdb.com/title/tt0120338/usercommen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10029</td>\n",
       "      <td>Titanic</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>Why do people bitch about this movie and not a...</td>\n",
       "      <td>http://www.imdb.com/title/tt0120338/usercommen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10030</td>\n",
       "      <td>Titanic</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>What's inexplicable? Firstly, the hatred towar...</td>\n",
       "      <td>http://www.imdb.com/title/tt0120338/usercommen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10031</td>\n",
       "      <td>Titanic</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>Previously, I wrote that I loved \"Titanic\", cr...</td>\n",
       "      <td>http://www.imdb.com/title/tt0120338/usercommen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id movie_name positive  stars                                               text                                                url\n",
       "0     10027    Titanic     True      7  Sure, Titanic was a good movie, the first time...  http://www.imdb.com/title/tt0120338/usercommen...\n",
       "1     10028    Titanic     True     10  When I saw this movie I was stunned by what a ...  http://www.imdb.com/title/tt0120338/usercommen...\n",
       "2     10029    Titanic     True     10  Why do people bitch about this movie and not a...  http://www.imdb.com/title/tt0120338/usercommen...\n",
       "3     10030    Titanic     True     10  What's inexplicable? Firstly, the hatred towar...  http://www.imdb.com/title/tt0120338/usercommen...\n",
       "4     10031    Titanic     True     10  Previously, I wrote that I loved \"Titanic\", cr...  http://www.imdb.com/title/tt0120338/usercommen..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMDB_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's download labMT, a word score list for sentiment analysis containing over 10,000 words. The file contains a \"happiness\" value, and ranks words by their happiness. It also includes mean and standard deviation, Twitter rank and Google rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = 'http://www.plosone.org/article/fetchSingleRepresentation.action?uri=info:doi/10.1371/journal.pone.0026752.s001'\n",
    "labmt = pd.read_csv(url, skiprows=2, sep='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>happiness_rank</th>\n",
       "      <th>happiness_average</th>\n",
       "      <th>happiness_standard_deviation</th>\n",
       "      <th>twitter_rank</th>\n",
       "      <th>google_rank</th>\n",
       "      <th>nyt_rank</th>\n",
       "      <th>lyrics_rank</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>laughter</th>\n",
       "      <td>1</td>\n",
       "      <td>8.50</td>\n",
       "      <td>0.9313</td>\n",
       "      <td>3600</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>1728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>happiness</th>\n",
       "      <td>2</td>\n",
       "      <td>8.44</td>\n",
       "      <td>0.9723</td>\n",
       "      <td>1853</td>\n",
       "      <td>2458</td>\n",
       "      <td>--</td>\n",
       "      <td>1230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>3</td>\n",
       "      <td>8.42</td>\n",
       "      <td>1.1082</td>\n",
       "      <td>25</td>\n",
       "      <td>317</td>\n",
       "      <td>328</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>happy</th>\n",
       "      <td>4</td>\n",
       "      <td>8.30</td>\n",
       "      <td>0.9949</td>\n",
       "      <td>65</td>\n",
       "      <td>1372</td>\n",
       "      <td>1313</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laughed</th>\n",
       "      <td>5</td>\n",
       "      <td>8.26</td>\n",
       "      <td>1.1572</td>\n",
       "      <td>3334</td>\n",
       "      <td>3542</td>\n",
       "      <td>--</td>\n",
       "      <td>2332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           happiness_rank  happiness_average  happiness_standard_deviation twitter_rank google_rank nyt_rank lyrics_rank\n",
       "word                                                                                                                    \n",
       "laughter                1               8.50                        0.9313         3600          --       --        1728\n",
       "happiness               2               8.44                        0.9723         1853        2458       --        1230\n",
       "love                    3               8.42                        1.1082           25         317      328          23\n",
       "happy                   4               8.30                        0.9949           65        1372     1313         375\n",
       "laughed                 5               8.26                        1.1572         3334        3542       --        2332"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labmt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a happiness dictionary of (word, valence) pairs where each valence is that word's original valence minus the average valence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "average = labmt.happiness_average.mean()\n",
    "happiness = (labmt.happiness_average - average).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save to disc\n",
    "fp = open(\"happiness.json\",\"w\")\n",
    "json.dump(happiness, fp)\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reopen\n",
    "with open(\"happiness.json\", \"r\") as fp:\n",
    "    happiness = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score(happy):  2.92476032088\n",
      "Score(miserable):  -2.83523967912\n",
      "Best score:  3.12476032088\n",
      "Worst score:  -4.07523967912\n"
     ]
    }
   ],
   "source": [
    "print \"Score(happy): \", happiness['happy']\n",
    "print \"Score(miserable): \", happiness['miserable']\n",
    "print \"Best score: \", max(happiness.values())\n",
    "print \"Worst score: \", min(happiness.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing and Saving Review Attributes Using Happiness Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's write a function to collect several attributes from a given review's text body, and save all valuable information into a new data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's write a function that removes stop words (all non important words from a valence perspective) from a text body."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import text\n",
    "stopwords = text.ENGLISH_STOP_WORDS\n",
    "punctuation = list('.,;:!?()[]{}`''\\\"@#$%^&*+-|-=~_')\n",
    "\n",
    "def removeStopWords(text, stopwords = stopwords):\n",
    "    new_text = \"\"\n",
    "    for word in text.split():\n",
    "        if word not in stopwords:\n",
    "            while len(word) != 0 and word[-1] in punctuation:\n",
    "                word = word[:len(word)-1]\n",
    "            new_text += word + ' '\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll write a function that returns total happiness, average happiness, total scorable words, and percentage of scorable words in a given review text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Name: getValenceInfo()\n",
    "Inputs: review text, dictionary of happiness\n",
    "Returns: a 4-tuple of (happiness total, happiness average, total # of scorable words, % of scorable words)\n",
    "'''\n",
    "def getValenceInfo(text, valenceDict):\n",
    "    total_words = len(text.split())\n",
    "    happiness_total, count_relevant = 0, 0\n",
    "    for word in text.split():\n",
    "        if word in valenceDict.keys():\n",
    "            count_relevant += 1\n",
    "            happiness_total += valenceDict[word]\n",
    "    if count_relevant != 0: \n",
    "        avg_valence = 1.*happiness_total/count_relevant\n",
    "    else: \n",
    "        avg_valence = 0\n",
    "    return happiness_total, avg_valence, total_words, 1.*count_relevant / total_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll write a function that, given a data frame, returns a new data frame with the concatenation of valence (happiness) info in 4 new columns: valence sum, valence average, # of scorable words, % of scorable words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Name: getAllInfo\n",
    "Input: data frame, happiness dictionary, list of stop words\n",
    "Returns: a new data frame with 4 new columns: valence_sum, valence_avg, n_scorables, pct_scorables\n",
    "'''\n",
    "def getAllInfo(df, valenceDict, stopwords): \n",
    "    valence_suml, valence_avgl, review_lenl, review_fractionl = [], [], [], []\n",
    "    for i, row in df.iterrows():\n",
    "        cleaned_review = removeStopWords(row['text'], stopwords)\n",
    "        valence_sum, valence_avg, review_len, review_fraction = getValenceInfo(cleaned_review, valenceDict)\n",
    "        valence_suml.append(valence_sum)\n",
    "        valence_avgl.append(valence_avg)\n",
    "        review_lenl.append(review_len)\n",
    "        review_fractionl.append(review_fraction)\n",
    "    conc = pd.DataFrame({'valence_sum': valence_suml, 'valence_avg':valence_avgl ,'n_scorables': review_lenl, \n",
    "                         'pct_scorables': review_fractionl})\n",
    "    return pd.concat([df, conc], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a new dataframe `valence_df` with the valence statistics run on our IMDB_df. This code takes a few minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 17s, sys: 1.08 s, total: 3min 18s\n",
      "Wall time: 3min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "valence_df = getAllInfo(IMDB_df, happiness, stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>movie_name</th>\n",
       "      <th>positive</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "      <th>n_scorables</th>\n",
       "      <th>pct_scorables</th>\n",
       "      <th>valence_avg</th>\n",
       "      <th>valence_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10027</td>\n",
       "      <td>Titanic</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "      <td>Sure, Titanic was a good movie, the first time...</td>\n",
       "      <td>http://www.imdb.com/title/tt0120338/usercommen...</td>\n",
       "      <td>120</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.479760</td>\n",
       "      <td>38.380826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10028</td>\n",
       "      <td>Titanic</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>When I saw this movie I was stunned by what a ...</td>\n",
       "      <td>http://www.imdb.com/title/tt0120338/usercommen...</td>\n",
       "      <td>65</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.508760</td>\n",
       "      <td>17.806611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10029</td>\n",
       "      <td>Titanic</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>Why do people bitch about this movie and not a...</td>\n",
       "      <td>http://www.imdb.com/title/tt0120338/usercommen...</td>\n",
       "      <td>75</td>\n",
       "      <td>0.586667</td>\n",
       "      <td>0.710669</td>\n",
       "      <td>31.269454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10030</td>\n",
       "      <td>Titanic</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>What's inexplicable? Firstly, the hatred towar...</td>\n",
       "      <td>http://www.imdb.com/title/tt0120338/usercommen...</td>\n",
       "      <td>235</td>\n",
       "      <td>0.587234</td>\n",
       "      <td>0.239253</td>\n",
       "      <td>33.016924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10031</td>\n",
       "      <td>Titanic</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>Previously, I wrote that I loved \"Titanic\", cr...</td>\n",
       "      <td>http://www.imdb.com/title/tt0120338/usercommen...</td>\n",
       "      <td>302</td>\n",
       "      <td>0.450331</td>\n",
       "      <td>0.189907</td>\n",
       "      <td>25.827404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id movie_name positive  stars                                               text                                                url  n_scorables  pct_scorables  valence_avg  valence_sum\n",
       "0     10027    Titanic     True      7  Sure, Titanic was a good movie, the first time...  http://www.imdb.com/title/tt0120338/usercommen...          120       0.666667     0.479760    38.380826\n",
       "1     10028    Titanic     True     10  When I saw this movie I was stunned by what a ...  http://www.imdb.com/title/tt0120338/usercommen...           65       0.538462     0.508760    17.806611\n",
       "2     10029    Titanic     True     10  Why do people bitch about this movie and not a...  http://www.imdb.com/title/tt0120338/usercommen...           75       0.586667     0.710669    31.269454\n",
       "3     10030    Titanic     True     10  What's inexplicable? Firstly, the hatred towar...  http://www.imdb.com/title/tt0120338/usercommen...          235       0.587234     0.239253    33.016924\n",
       "4     10031    Titanic     True     10  Previously, I wrote that I loved \"Titanic\", cr...  http://www.imdb.com/title/tt0120338/usercommen...          302       0.450331     0.189907    25.827404"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valence_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert True/False to 1/0: needed to make valence_df JSON serializable, also better practice\n",
    "valence_df.positive = 1.0*valence_df.positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save to disc\n",
    "fp = open(\"valence_df_dict.json\",\"w\")\n",
    "json.dump(valence_df.to_dict(), fp)\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"valence_df_dict.json\", \"r\") as fp:\n",
    "    valence_df_dict = json.load(fp)\n",
    "valence_df = pd.DataFrame(valence_df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
